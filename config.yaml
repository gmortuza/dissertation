# ================ Configuration for Model ===============
output_dir: outputs___
validation_split: .1
test_split: .1
batch_size: 32
num_epochs: 10000
learning_rate: 0.0001
weight_decay: 0.001
model_type: custom_model
save_summary_steps: 40 # batch
load_checkpoint: True
save_model_after_each_epoch: 100
total_training_example: 100  # -1 means all the training examples
resolution_slap:
  - 32
  - 64
  - 128
  - 256
  - 512
save_model_based_on: JI_16
JI_metrics_from_epoch: 1
output_threshold: 0.001

# ================ General settings ===============
input_dir: simulated_data_multi  # This output directory will be the input directory of the model
simulated_file_name: data
log_to: console  # console
device: cuda:0
log_level: info  # info, debug, warning, error
num_of_process: 1
use_seed: True  # Get the same result all the time. For debugging purpose
progress_bar_disable: False
save_for_picasso: True  # This will save both the raw file and ground truth compatible with picasso

# ================ Point extraction ===============
location_multiplier: 100
extracted_patch_size: 30
point_extraction_method: 'nn'  # weighted_mean, scipy, picasso
point_extractor_weight_path:  '/data/golam/dnam_nn/outputs_02_06_18_58_35/checkpoint/pointsbest.pth.tar' # path of the neural network weight for point extraction


# ================ Camera Settings ===============
# Padding in each framed
# Origami won't be present in the border regions
frame_padding: 6
Camera: Simulation
total_frames: 40000  # Total Number of frames
split_into: 4 # Total number of frames will be splitted into this amount of files
image_size: 32  # height and width will be the same
# This is the maximum number of emitter in a single that the neural network will predict.
# Depending on the probability distribution a frame might have more than this amount of emitter
max_number_of_emitter_per_frame: 30
Camera_integration_time: 300  # (ms)
Camera_Pixelsize: 107  # (nm)
data_gen_type: 'multiple_distribute'  # 'multiple_distribute' or 'single_distribute'
# create image of 64 times resolution then crop the emitters put in different resolution images
single_distribute_max_resolution: 64


# ================ Origami Settings ===============
distance_x: 10  # Distance between each binding site. (nm)
distance_y: 10  # (nm)
origami_row: 6
origami_column: 8
unique_origami: 15
total_origami: 100  # Total number of origami in the whole movie. This is the sum of all the unique origami occurance
# Total percent of binding site that will actually have the blinking event
# For some reason not all binding site have the blinking event
# Float value ranging 0.0 - 1.0
binding_site_incorporation: 1.0
# 0 --> not randomly oriented, 1 --> Randomly oriented
origami_orientation: 1
# 0 --> The distance of each origami is evenly distributed
# 1 --> The distance of each origami is randomly distributed ( Origami is placed randomly in the frame)
origami_arrangement: 1
origami_3d: 0
origami_mean: False # Center of the mass of
# Adding drift
drift_x: 0  # Drift in nanometer in x direction for each 1000 frame
drift_y: 0  # Drift in nanometer in y direction for each 1000 frame
# Drift will be added in the whole frame
# linear --> Evenly distribute the drift among 1000 frames
# random_walk --> Randomly choose the drift from the normal distribution of mean 0 and SD 50/1000
drift_method: linear  # we can also put random walk

# Number of localization event that will blink all the frames
num_gold_nano_particle: 0
# total number of photons
photons_for_each_gold_nano_particle: 45000000

# ================ Noise Settings ===============
noise_level: 20  # Noise level  # (Background Level in GUI)

# noise_type: options: gaussian/poisson
noise_type: poisson


# ================ Imager parameters ===============
Imager_Constant Photonrate Std: 0  # Constant detection rate(select box)
Imager_Laserpower: 1.5  # Power density (kwCm-2)
Imager_PSF: 1.32  # point spread function (px)
Imager_Photonbudget: 1500000.0  #
Imager_Photonslope: 35  # Photon detection rate
# From the file
power_density_conversion: 20
laserc_default: 0.012063
imagec_default: 0.003195
std_factor: 1.82



# ================ Paint parameters ===============
PAINT_imager: 5.0  # Imager concentration (nm)
PAINT_k_on: 1600000.0  # M-1s-1
PAINT_tau_b: 500.0  # Bright Time


# ================ Neptune setup ===============
neptune_name: "multi model"
neptune_description: "Two model each increase by 4 times. L1 loss. Subpixel for upsampling. UNet--transpose conv"
neptune_project: "golammdmortuza/dnam-nn"
neptune_api_key: "eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIwMjQyYzgzOC04MWVjLTRkZTMtYTExZC1kMGEzMDllNDZmZTcifQ=="
neptune_mode: 'debug'  # async / sync / offline / read-only / debug /
neptune_code_snapshot:
  - models/custom.py
  - models/unet.py
  - data_loader.py
neptune_tags:
  - weight_decay
  - multi_distribute
  - weight_decay_value_0
  - adamW